\documentclass[12pt] {article}
\usepackage{amsmath, amssymb, amsfonts}
\begin{document}

\title{Modelling Process Notes}
\author{Alexander Bailey}
\maketitle

\section{Modelling Process}
\subsection*{Factors}
Anything that will have some effect on the your calculations e.g. drag, friction, mass, buoyancy, area.
Note that separate things qualities will count separately e.g. a triangle's area and a square's.

\subsection*{Assumptions}
A statement that makes the problem simpler - cancels factors. 
e.g. 'Total length of wood is not reduced when it is cut'
or 'There are no significant currents' 

\subsection*{Precise Problem Statement}
Given (key factors and assumptions), Find (the value you're asked to find)

\subsection*{Formulating a Model}
\begin{equation*}
x \propto y,1/z \implies x = \frac{ky}{z} 
\end{equation*}

\subsection*{Modelling Forces}
Use Newton's 2nd law, subtract negative forces and add positive ones. Use the ones from the list.

\section{Differentiation}
\subsection*{Implicit Differentiation}
\subsection*{Series and Approximation}
\subsection*{Numerical Differentiation}
\section{Integration}
\subsection*{Integration Techniques}
\begin{enumerate}
  \item U substitution 
  \item Integration by Parts
\end{enumerate}
\subsection*{Partial Fractions}

\section{Ordinary Differential Equations}
Ordinary differential equations are equations containing one or more functions of one independent variable. 
You can recognise an ODE from a PDE (partial differential equation) because a PDE will contain $\partial$ (pronounced 'del')
and ODEs have standard 'd'. $\frac{dy}{dx}$ means $y$ is the dependent variable and $x$ is the independent variable. $\frac{dx}{dt}$ $x$ is dependent, $t$ is independent.

\subsection*{Properties}
\subsubsection*{Order}
Highest derivative (also equal to number of values needed to find a particular solution) e.g.
\begin{align*}
    &\frac{dy}{dx} = 5x \text{ is 1st Order} \\
    &\frac{d^4y}{dx^4} = \frac{dy}{dx} + 2 \text{ is 4th Order} \\
\end{align*}

\subsubsection*{Linear}
Involves only derivatives of y and terms of y to the 1st power e.g. ONLY $\frac{dy}{dx}$, $y$ etc.
\begin{align*}
    &\frac{d^4y}{dx^4} + \frac{dy}{dx} = 2 \text{ is linear} \\
    &\frac{dy}{dx} = 2y + 3 \text{ is linear} \\
\end{align*}

\subsubsection*{Homogeneity} 
If all (non-zero) terms involve the dependent variable then the equation is homogeneous
\begin{align*}
    &\frac{dx}{dt} = x \text{ is homogeneous} \\
    &\frac{dy}{dx} = 2y + 3 \text{ is not homogeneous (3 doesn't involve x)} \\
\end{align*}

\subsection*{Forming Differential Equations}
In typical exam questions there are few points at which you will form a differential equation: modelling a set 
of forces in the typical modelling questions, using proportionality or previous knowledge. Typically the modelling 
questions will use Newton's 2nd law which states $\sum F = ma$ and then you can sum the forces and use it to find
mass/acceleration (or their derivatives). 

\subsection*{Solving Differential Equations}
\begin{enumerate} 
    \item Direct Integration
    \item Separation of Variables 
    \item Euler's Method    
    \item Integrating Factor
    \item Exponential Substitution
\end{enumerate}

\subsubsection*{Euler's Method}
Euler's method is a numerical method for solving D.E.s that uses a 2 term Taylor Series 
and is simply stated by the equation.
\begin{equation*}
  f(x+h) \approx f(x) + hf'(x)
\end{equation*}
These questions are easiest to complete if you use a table for the values 
of $x$, $f(x)$, $f'(x)$ and then calculate $f(x+h)$ e.g.
\vspace{1em}
\newline
$\begin{array}{c|c|c|c}
  x & f(x) & f'(x) & f(x) + hf'(x) \\
  1 & 1^2 & 2 & 4 \\
  4 & \dots & \dots & \dots \\
\end{array}$

\subsubsection*{Exponential Substitution}
Exponential Substitution allows you to solve a 2nd order O.D.E using something called
a `characteristic equation'. You substitute in a trial solution $e^{\lambda t}$
and then complete the substitution (differentiate) and then divide through by your 
trial solution leaving you with the characteristic equation which you can then solve for
$\lambda$. You then substitute your values into the equation:
\begin{equation*}
  x=C_1e^{\lambda t} + C_2e^{\lambda t} \\
\end{equation*}
This is a general solution, to calculate the exact solution you need two points 
(for a 2nd order equation) to calculate values of $C_1$ and $C_2$. e.g
\begin{gather*}
  \frac{d^2x}{dt^2} - \frac{dx}{dt} -6x =0 \\
  \lambda^2 - \lambda - 6 = 0\\
  \implies \lambda=3,-2 \\
  x=c_1e^{3t} + c_2e^{-2t} \text{ gen. soln.} \\
  \text{Given x(0) = 0, x'(0)=5} \\
  0 = C_1 + C_2 \implies C_1 = -C_2 \\
  5 = 3C_1 + -2C_2 \implies C_2 = -1 \\
  \implies C_1 = 1 \\
  x=e^{3t} - e^{-2t} \text{ exact soln.} \\
\end{gather*}

\subsubsection*{Integrating Factor}
\begin{equation*}
\text{if } h(x)=\int p(x)dx
\end{equation*}
\begin{equation*}
  \frac{dy}{dx} + p(x)y = r(x) \text{ has solution } y = e^{-h(x)} \int e^{h(x)}r(x)dx
\end{equation*}

\section{Probability}
\subsection*{Some General Rules}
\begin{align*}
  Pr(A \vert B) &= \text{Probability of A happening given B has already happened} \\
                &= \frac{Pr(A\&B)}{Pr(B)} \\
  Pr(A \& B) &= Pr(A) \times Pr(B) \text{ If they are independent}
\end{align*}
\subsection*{Continuous Random Variables}
Continuous Random Variables that are infinite i.e height as there are an infinite amount 
of possible heights with infinite accuracy. When graphed the area under a graph (probability density function)
will always sum to one i.e
\begin{equation*}
  \int_\infty^\infty f(x)dx = 1 
\end{equation*}
\subsection*{Bayes Theorem}
\begin{equation*}
  Pr(A \vert B) = \frac{Pr(A)}{Pr(A)Pr(B \vert A) + Pr(~A)Pr(B \vert ~A)}
\end{equation*}

\section{Vectors}
\newpage
\section{Matrices}
Vectors are just a special case of Matrices (one column/row) so a lot of their properties
are shared with matrices. For instance, addition/subtraction are performed component wise 
and scalar multiplication works just like it does in vectors i.e
\begin{equation*}
  \begin{bmatrix}
    a & d \\
    b & e \\
    c & f \\
  \end{bmatrix}
  + 
  \begin{bmatrix}
    g & j \\
    h & k \\
    i & l \\
  \end{bmatrix}
  =
  \begin{bmatrix}
    a+g & d+j \\
    b+h & e+k \\
    c+i & f+l \\
  \end{bmatrix}
\end{equation*}
\begin{equation*}
  3
  \begin{bmatrix}
    -1 & 0 \\
    2 & 1 \\
  \end{bmatrix}
  =
  \begin{bmatrix}
    -3 & 0 \\
    6 & 3 \\
  \end{bmatrix}
\end{equation*}
The only thing you will need to keep in mind for matrix addition/subtraction is 
that you can only add matrices of the same order. What's order?

\subsection*{Order of Matrices}
By convention, the order of a matrix is expressed like $m \times n$. Where m is the number
of rows and n the number of columns. This is opposite to the traditional `$x$ \& $y$' way
of thinking but you'll see why when you get to multiplication.

\subsection*{Transpose}
The first of the new operations we will learn for matrices is something called `transpose'.
You can think of this like the rotation of a matrix. It is represented by a superscript capital T.
\begin{equation*}
  \begin{bmatrix} 
    1 \\
    2 \\
    1 \\
  \end{bmatrix} 
  ^\intercal
  =
  \begin{bmatrix}
    1 & 2 & 1 
  \end{bmatrix}
\end{equation*}
\begin{equation*}
  \begin{bmatrix} 
    0 & -2 \\
    2 & 12 \\
    0 & -3 \\
  \end{bmatrix} 
  ^\intercal
  =
  \begin{bmatrix} 
    -2 & 12 & 3 \\
     0 & 2 & 0 \\
  \end{bmatrix} 
\end{equation*}
\newpage

\subsection*{Matrix Multiplication}
For two $m \times n$ matrices, 
\begin{itemize}
  \item Cover everything but the first column in the second matrix
  \item Take the dot product (just like vectors) of that and each of the m rows of the first matrix (where the first is the first row of the matrix output, the second the second row etc)
  \item Repeat for each of the $n$ columns in the second matrix
\end{itemize}
For two $m \times n$ matrices, the first must have the same number of rows as columns in the
second. 

\subsubsection*{Example}
\begin{gather*}
  \begin{bmatrix}
    1 & 3 & 1 \\
    2 & 4 & 5 \\
    6 & 1 & 2 \\
  \end{bmatrix}
  \begin{bmatrix}
    2 & 3 & 1 \\
    4 & 2 & 1 \\
    6 & 1 & 1 \\
  \end{bmatrix}
  =
  \begin{bmatrix}
    20 & 10 & 5 \\
    50 & 19 & 11 \\
    28 & 22 & 9 \\
  \end{bmatrix}
  \\
  \begin{bmatrix}
    [1 & 3 & 1] \\
    [2 & 4 & 5] \\
    [6 & 1 & 2] \\
  \end{bmatrix}
  \begin{bmatrix}
    2 & 3 & 1 \\
    4 & 2 & 1 \\
    6 & 1 & 1 \\
  \end{bmatrix} 
  \\
  [2, 4, 6]\cdot [1, 3, 1] = 2\cdot1 + 4\cdot3 + 6\cdot1 = 20
\end{gather*}

\subsection*{Matrix Multiplication as a Transformation}
Taking two equations, that move two points $x$ and $y$ to two new points $x_{new}$ and $y_{new}$. 
\begin{align*}
  2x - y = x_{new} \\
  x + y = y_{new}
\end{align*}
These can be represented as matrices, (the matrix containing the co-efficients
is called a `transformation matrix')
\begin{equation*}
  \begin{bmatrix}
    2 & -1 \\
    1 & 1 
  \end{bmatrix}
  \begin{bmatrix}
    x \\
    y 
  \end{bmatrix}
  =
  \begin{bmatrix}
    x_{new} \\
    y_{new}
  \end{bmatrix}
\end{equation*}
\end{document}
